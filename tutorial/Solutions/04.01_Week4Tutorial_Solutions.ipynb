{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Python for Data Exploration and Statistics\n",
    "\n",
    "\n",
    "Thus far we have been learning Python basics. These are great for computer scientists, but of course, what we as social scientists and humanists want to do is analyze data (which we learned last week is objectified information!). This week we'll analyze reall data using our first Python module, also called a library or package, called Pandas. A module is simply bundles of functions other people wrote that you will then re-use. You have to first install a module before you can use it. If you installed the Anaconda distribution of Python Pandas, and most of the modules we will use, comes pre-installed. If you did not install the Anaconda distribution you will have to install Pandas yourself (using `pip` or some other method).\n",
    "\n",
    "Like Python, each module has its own syntax that you have to learn how to write correctly. We'll start to learn the Pandas syntax today.\n",
    "\n",
    "<i>Pandas</i> is a popular and flexible package whose primary use is its datatype: the <i>DataFrame</i>. The dataframe is essentially a spreadsheet, like you would find in Excel, but it has some tricks up its sleeve!\n",
    "\n",
    "As we will see, Pandas allows us to do basic statistics easily, allows us to compare columns, and allows us to do quick and easy visualizations. \n",
    "\n",
    "We will keep practicing these uses of Pandas throughout the semester. Today, I'm just planting the seed.\n",
    "\n",
    "\n",
    "# Reminder: our growing Python toolkit\n",
    "\n",
    "It's always helpful to keep in mind all the tools we have learned. We will continue to use these throughout the semester. I'll list some important ones here, just to keep reinforcing what we've learned.\n",
    "\n",
    "* values (e.g. `1.2`, `100`, `'Hello, Boston!'`)\n",
    "* variables (e.g., `float`, `int`, `string`)\n",
    "* operators (e.g., `=`, `+`, `-`)\n",
    "* logical operators (e.g., `==`, `>`, `<`, `>=`)\n",
    "* statements and expressions (e.g. `10 + 500`)\n",
    "* built-in functions (e.g. `print()`, `type()`)\n",
    "* string functions and string methods (e.g., `string.lower()`, `string.islower()`)\n",
    "* list functions and list metods (e.g., `len(mylist)`, `mylist.append()`)\n",
    "* conditionals (e.g., `if`, `else`, `elif`)\n",
    "* loops (e.g., `for` loops)\n",
    "* user-defined functions (using `def`)\n",
    "\n",
    "# Relative File Structures\n",
    "\n",
    "We will need to read in a file from our hard drive (our secondary memory) into our primary memory. We're going to use Pandas functions to do this today, as we'll be working with dataframes, but later we'll read in plain text files.\n",
    "\n",
    "We will use the *relative* file structure to do so, in order to make our code reproducible. You should put this script in your `scripts` folder, and you should put the .csv in your `data` folder. If you don't do this correctly, you'll get an error below that we'll trouble shoot.\n",
    "\n",
    "I found [this blog] (https://desktop.arcgis.com/en/arcmap/10.3/tools/supplement/pathnames-explained-absolute-relative-unc-and-url.htm) offers a good explanation for files and file structures. To quote from that blog:\n",
    "\n",
    "> Relative path\n",
    "> A relative path refers to a location that is relative to a current directory. Relative paths make use of two special symbols, a dot (.) and a double-dot (..), which translate into the current directory and the parent directory. Double dots are used for moving up in the hierarchy. A single dot represents the current directory itself.\n",
    "> \n",
    "> In the example directory structure below, assume you used Windows Explorer to navigate to D:\\Data\\Shapefiles\\Soils. After navigating to this directory, a relative path will use D:\\Data\\Shapefiles\\Soils as the current directory (until you navigate to a new directory, at which point the new directory becomes the current directory). The current directory is sometimes referred to as the root directory.\n",
    "> \n",
    "> If you wanted to navigate to the Landuse directory from the current directory (Soils), you could type the following in the Windows Explorer Address box:\n",
    "> \n",
    "> ..\\\\Landuse\n",
    "Windows Explorer would navigate to D:\\Data\\Shapefiles\\Landuse. A few more examples using D:\\Data\\Shapefiles\\Landuse as the current directory are below:\n",
    "> \n",
    "> ..               (D:\\Data\\Shapefiles)  \n",
    "> ..\\\\..            (D:\\Data)  \n",
    "> ..\\\\..\\Final      (D:\\Data\\Final)  \n",
    "> .                (D:\\Data\\Shapefiles\\Landuse - the current directory)  \n",
    "> .\\\\..\\Soils       (D:\\Data\\Final\\Soils)  \n",
    "> ..\\\\..\\\\.\\Final\\\\..\\Shapefiles\\.\\Landuse  (D:\\Data\\Shapefiles\\Landuse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pandas Dataframe\n",
    "\n",
    "We're going to jump into Pandas using real data.\n",
    "\n",
    "******************************\n",
    "The data we'll analyze today comes from:\n",
    "\n",
    "National Center for Education Statistics, United States Department of Education. (2009). Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) [Data file]. Available from http://nces.ed.gov/ecls/kindergarten.asp\n",
    "\n",
    "I selected five variables (columns) to analyze:\n",
    "\n",
    "* reading_score = READING IRT SCALE SCORE\n",
    "* math_score = MATH IRT SCALE SCORE\n",
    "* knowledge_score = GENERAL KNOWLEDGE IRT SCALE SCORE\n",
    "* p2income = TOTAL HOUSEHOLD INCOME\n",
    "* incomecat = INCOME CATEGORES\n",
    "    * 1 = low income: < \\$40,000\n",
    "    * 2 = mid income\n",
    "    * 3 = high income: >= \\$70,000\n",
    "    \n",
    "The unit of observation (row) is the individual kindergartner. The file is a comma-separated file, with utf-8 encoding.\n",
    "   \n",
    "## Motivating Question\n",
    "\n",
    "**Are math, reading, and general knowledge scores related to household income in any predictable way?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our library\n",
    "#this is the simplest way to import a module\n",
    "# if you get a `module not found` error it means you have not installed this particular module\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Python more generally, Pandas relies on functions. These are not in-built functions in Python, but Pandas-specific functions. We will use the `read_csv()` function, and note the `pandas` prefix: `pandas.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note the relative file structure\n",
    "#We'll go up one directory, and then down into the `data/` directory:\n",
    "\n",
    "df = pandas.read_csv(\"../data/education_dataset.csv\", sep=',', encoding='utf8')\n",
    "\n",
    "#always check your data type!\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's a pandas object - only pandas functions will work on it\n",
    "#Let's take a look using the head() function\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#or view the entire dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe slicing \n",
    "\n",
    "Like list and string slicing, but with some quirks to use with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#syntax to extract columns\n",
    "df['reading_score'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reminder, you can look at the entire thing:\n",
    "df['reading_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract one row: notice the syntax\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Ok, we know what we want to do with quantitative dataframes, we want to summarize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary statistics\n",
    "df['reading_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reading_score'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reading_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, we can find it all at the same time (for quantitative columns)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between means \n",
    "\n",
    "What if we want to know if the mean is different across categories? This is one of the more common uses of data analysis. For example, we might want to know of the average wage is different for men and women. We don't have gender in our data, but we do have income category (see the description above). We'll use that to compare means across our three scores. Remember our motivating question:\n",
    "\n",
    "**Are math, reading, and general knowledge scores related to household income in any predictable way?**\n",
    "\n",
    "\n",
    "First step, are the average different for each of our income categories?\n",
    "\n",
    "To do so, we can use two methods.\n",
    "\n",
    "First, the \"manual\" method. We'll use boolean statements to create three separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use of boolean operators with dataframes:\n",
    "\n",
    "df['incomecat']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice out the rows where the condition is true, and \n",
    "df[df['incomecat']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it as a new variable, including our other income categories:\n",
    "df_incomecat1 = df[df['incomecat']==1]\n",
    "df_incomecat2 = df[df['incomecat']==2]\n",
    "df_incomecat3 = df[df['incomecat']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, print our our means\n",
    "\n",
    "print(df_incomecat1['reading_score'].mean())\n",
    "print(df_incomecat2['reading_score'].mean())\n",
    "df_incomecat3['reading_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas has a way to do this without creating new dataframews! The Pandas groupby function\n",
    "#create a new dataframe that is grouped by income category\n",
    "\n",
    "df_grouped = df.groupby('incomecat')\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['reading_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "We can also use visualizations to explore our data. We'll just touch on this today. We'll learn how to make pretty visualizations later.\n",
    "\n",
    "We'll use another library for this: `matplotlib`, the most popular Python visualization libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note the different syntax here, we're going to rename the library to something shorter when we import it\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always start with histograms!\n",
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#That's not pretty. Let's show just one\n",
    "\n",
    "df['knowledge_score'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other options:\n",
    "#Scatter plot: is math and reading scores correlated?\n",
    "#note the synax: this is the basic syntax for plotting\n",
    "\n",
    "df.plot(kind='scatter', x = 'reading_score', y = 'math_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot average by income\n",
    "## remember our grouped by plot\n",
    "## Let's first make another dataframe from it\n",
    "\n",
    "df_grouped_mean = df_grouped.mean()\n",
    "df_grouped_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can plot this like we would the original dataframe!\n",
    "\n",
    "df_grouped_mean.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not great! What's the issue?\n",
    "\n",
    "#Let's pull out three columns: notice the syntax - double brackets!\n",
    "\n",
    "df_grouped_mean[['reading_score', 'math_score', 'knowledge_score']].plot(kind='bar')\n",
    "plt.legend(loc=9, bbox_to_anchor=(0.5, -0.2), ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1: Slice out and print the knowledge score column from the dataframe (df)\n",
    "df['knowledge_score'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 2: extract the third row in the dataframe (careful! remember that Python indexes start at 0)\n",
    "\n",
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exercise 3: find the mean, median, and standard deviation for the knowledge score column.\n",
    "# Note: I didn't teach you median, but see if you can recognize patterns and intuit how to do it.\n",
    "\n",
    "print(df['knowledge_score'].mean())\n",
    "print(df['knowledge_score'].median())\n",
    "print(df['knowledge_score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 4: print out the mean knowledge score separately \n",
    "# for those in income categories 1, 2, and 3 respetively.\n",
    "\n",
    "df_grouped['knowledge_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 5: produce a histogram of the knowledge score column\n",
    "\n",
    "df['knowledge_score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 6: just based on visuals alone, is there a stronger relationship between math score and general knowledge,\n",
    "#Or reading score and general knowledge?\n",
    "df.plot(kind='scatter', x = 'reading_score', y = 'knowledge_score')\n",
    "df.plot(kind='scatter', x = 'math_score', y = 'knowledge_score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Do something creative! What other visualizations can you produce? What other relationships?\n",
    "# Maybe produce different scatter plots from our three dataframes from the different income categores\n",
    "# e.g. df_incomecat1, df_incomecat2, df_incomecate3.\n",
    "# Are the relationships between variables stronger in different income categories? (visually inspected)\n",
    "\n",
    "# If you want, check out the matplotlib documentation and see if you can do things like change colors,\n",
    "# change axis names, or other features of your visualizations.\n",
    "\n",
    "df_grouped_mean[['reading_score', 'math_score', 'knowledge_score']].T.plot(kind='bar')\n",
    "plt.legend(loc=9, bbox_to_anchor=(0.5, -0.4), ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_mean.plot(kind='scatter', x = 'reading_score', y = 'knowledge_score')\n",
    "df_grouped_mean.plot(kind='scatter', x = 'math_score', y = 'knowledge_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
